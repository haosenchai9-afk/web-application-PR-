#!/usr/bin/env python3
# =============================================================================
# GitHub PR Automation Workflow Verification Scriptï¼ˆæ ·ä¾‹ï¼šweb-applicationä»“åº“ï¼‰
# =============================================================================
# éªŒè¯ç›®æ ‡ï¼šweb-applicationä»“åº“çš„PRè‡ªåŠ¨åŒ–å·¥ä½œæµï¼ˆpr-automation.ymlï¼‰
# ä¾èµ–ï¼šrequests, python-dotenv, base64ï¼Œéœ€æå‰é…ç½® .github_env ç¯å¢ƒå˜é‡
# =============================================================================

import sys
import os
import requests
import time
import datetime
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv
import base64


# -----------------------------
# 1) é…ç½®å‚æ•°ï¼ˆå·²æ›¿æ¢ä¸ºweb-applicationä»“åº“å®é™…å€¼ï¼‰
# -----------------------------
CONFIG = {
    # ä»£ç å¹³å°åŸºç¡€é…ç½®ï¼ˆGitHubå›ºå®šï¼‰
    "CODE_PLATFORM": {
        "name": "GitHub",
        "api_domain": "github.com",
        "auth_scheme": "token",
        "default_repo": "web-template-repo",  # å›¢é˜Ÿé»˜è®¤æµ‹è¯•ä»“åº“
        "target_repo": "web-application",     # ç›®æ ‡éªŒè¯ä»“åº“
        "api_per_page": 100,                  # å•æ¬¡APIæœ€å¤§è¿”å›100æ¡æ•°æ®
        "max_workflow_wait": 600              # ä¸»PRå·¥ä½œæµæœ€å¤§ç­‰å¾…10åˆ†é’Ÿï¼ˆ600ç§’ï¼‰
    },

    # ç¯å¢ƒä¸è®¤è¯é…ç½®ï¼ˆ.github_envå­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼‰
    "ENVIRONMENT": {
        "env_file": ".github_env",            # ç¯å¢ƒå˜é‡æ–‡ä»¶
        "token_var": "GITHUB_TOKEN",          # Tokenå˜é‡å
        "org_var": "GITHUB_ORG"               # ç»„ç»‡å˜é‡åï¼ˆå€¼ä¸º"web-dev-team"ï¼‰
    },

    # å·¥ä½œæµé…ç½®ï¼ˆPRè‡ªåŠ¨åŒ–å·¥ä½œæµå…·ä½“ä¿¡æ¯ï¼‰
    "WORKFLOW": {
        "file_path": ".github/workflows/pr-automation.yml",  # å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        "workflow_filename": "pr-automation.yml",            # å·¥ä½œæµæ–‡ä»¶å
        "required_triggers": ["opened", "synchronize", "reopened"],  # å¿…éœ€è§¦å‘äº‹ä»¶
        "required_jobs": [                              # å¿…éœ€ä½œä¸šï¼ˆ4ç±»æ ¸å¿ƒæ ¡éªŒï¼‰
            "code-quality", "testing-suite", 
            "security-scan", "build-validation"
        ],
        "parallel_check_threshold": 120                 # ä½œä¸šå¹¶è¡Œåˆ¤å®šé˜ˆå€¼ï¼š120ç§’
    },

    # ä¸»PRé…ç½®ï¼ˆå®ç°PRè‡ªåŠ¨åŒ–çš„æ ¸å¿ƒPRï¼‰
    "MAIN_PR": {
        "title": "feat: add PR automation workflow (code-quality/test/security/build)",  # PRæ ‡é¢˜
        "source_branch": "feat/pr-automation",          # æºåˆ†æ”¯ï¼ˆå¼€å‘åˆ†æ”¯ï¼‰
        "target_branch": "main"                         # ç›®æ ‡åˆ†æ”¯ï¼ˆä¸»åˆ†æ”¯ï¼‰
    },

    # å•å…ƒæµ‹è¯•é…ç½®ï¼ˆ4ç±»å¤±è´¥åœºæ™¯æµ‹è¯•ç”¨ä¾‹ï¼‰
    "UNIT_TEST": {
        "test_cases": [
            # ç”¨ä¾‹1ï¼šä»£ç è´¨é‡å¤±è´¥ï¼ˆESLintè¿è§„ï¼šæœªå£°æ˜å˜é‡ç›´æ¥ä½¿ç”¨ï¼‰
            {
                "title": "Test: Code Quality Failure (ESLint Error)",
                "branch": "test-code-quality-fail",
                "file_path": "src/utils/test-lint-fail.js",
                "content": "// æ•…æ„è§¦å‘ESLint no-undefè§„åˆ™ï¼ˆæœªå£°æ˜å˜é‡ï¼‰\nconsole.log(undefinedVar);",
                "expected_failure": "code-quality"  # é¢„æœŸå¤±è´¥ä½œä¸š
            },
            # ç”¨ä¾‹2ï¼šæµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼ˆJestæ–­è¨€é”™è¯¯ï¼š1â‰ 2ï¼‰
            {
                "title": "Test: Testing Suite Failure (Jest Assert Error)",
                "branch": "test-testing-fail",
                "file_path": "tests/utils/test-fail.test.js",
                "content": "// æ•…æ„è§¦å‘Jestæ–­è¨€å¤±è´¥\nconst sum = (a,b) => a+b;\ntest('sum 1+1 should be 2', () => {\nexpect(sum(1,1)).toBe(3); // é”™è¯¯ï¼šé¢„æœŸ2å®é™…3\n});",
                "expected_failure": "testing-suite"  # é¢„æœŸå¤±è´¥ä½œä¸š
            },
            # ç”¨ä¾‹3ï¼šå®‰å…¨æ‰«æå¤±è´¥ï¼ˆç¡¬ç¼–ç APIå¯†é’¥ï¼‰
            {
                "title": "Test: Security Scan Failure (Hardcoded Secret)",
                "branch": "test-security-fail",
                "file_path": "src/api/security-test.js",
                "content": "// æ•…æ„è§¦å‘å®‰å…¨æ‰«æï¼šç¡¬ç¼–ç APIå¯†é’¥\nconst apiKey = 'sk_test_1234567890abcdef'; // æ•æ„Ÿä¿¡æ¯ç¡¬ç¼–ç ",
                "expected_failure": "security-scan"  # é¢„æœŸå¤±è´¥ä½œä¸š
            },
            # ç”¨ä¾‹4ï¼šæ„å»ºéªŒè¯å¤±è´¥ï¼ˆå¼•ç”¨ä¸å­˜åœ¨çš„ä¾èµ–åŒ…ï¼‰
            {
                "title": "Test: Build Validation Failure (Missing Dependency)",
                "branch": "test-build-fail",
                "file_path": "src/components/test-build-fail.js",
                "content": "// æ•…æ„è§¦å‘æ„å»ºå¤±è´¥ï¼šå¼•ç”¨ä¸å­˜åœ¨çš„ä¾èµ–\nimport nonExistentLib from 'non-existent-lib';\nconst TestComponent = () => <div>{nonExistentLib.render()}</div>;\nexport default TestComponent;",
                "expected_failure": "build-validation"  # é¢„æœŸå¤±è´¥ä½œä¸š
            }
        ],
        "max_test_wait": 300,  # æµ‹è¯•PRå·¥ä½œæµæœ€å¤§ç­‰å¾…5åˆ†é’Ÿï¼ˆ300ç§’ï¼‰
        "cleanup_enabled": True  # æµ‹è¯•åè‡ªåŠ¨æ¸…ç†PRå’Œåˆ†æ”¯
    },

    # PRè¯„è®ºè‡ªåŠ¨åŒ–é…ç½®ï¼ˆæœºå™¨äººåŠå¿…éœ€æŠ¥å‘Šï¼‰
    "PR_COMMENT": {
        "bot_login": "github-actions[bot]",  # GitHub Actionsé»˜è®¤æœºå™¨äººè´¦å·
        "required_reports": [                # å¿…éœ€çš„4ç±»è‡ªåŠ¨åŒ–æŠ¥å‘Š
            {
                "name": "Code Quality Report",  # ä»£ç è´¨é‡æŠ¥å‘Š
                "main_keywords": ["Code Quality Check Results", "ESLint"],  # ä¸»å…³é”®è¯
                "sub_keywords": ["Pass Rate: 100%", "Total Issues: 0"]       # å­å…³é”®è¯ï¼ˆæ— é”™è¯¯ï¼‰
            },
            {
                "name": "Test Coverage Report",  # æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
                "main_keywords": ["Test Coverage Results", "Jest"],
                "sub_keywords": ["Coverage: 85%+"]
            },
            {
                "name": "Security Scan Report",  # å®‰å…¨æ‰«ææŠ¥å‘Š
                "main_keywords": ["Security Scan Results", "Secret Detection"],
                "sub_keywords": ["No Secrets Found"]
            },
            {
                "name": "Build Validation Report",  # æ„å»ºéªŒè¯æŠ¥å‘Š
                "main_keywords": ["Build Check Results", "Webpack"],
                "sub_keywords": ["Build Successful"]
            }
        ]
    }
}


# -----------------------------
# 2) å·¥å…·å‡½æ•°ï¼ˆGitHub APIäº¤äº’ä¸åŸºç¡€æ“ä½œï¼Œé€šç”¨æ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def _get_github_api(
    endpoint: str, headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, Optional[Dict]]:
    """è°ƒç”¨GitHub APIï¼ˆGETï¼‰ï¼Œè¿”å›ï¼ˆæˆåŠŸçŠ¶æ€ï¼Œå“åº”æ•°æ®ï¼‰"""
    url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/{endpoint}"
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return True, response.json()
        elif response.status_code == 404:
            print(f"APIä¿¡æ¯: {endpoint} æœªæ‰¾åˆ° (404)", file=sys.stderr)
            return False, None
        else:
            print(f"APIé”™è¯¯ ({endpoint}): çŠ¶æ€ç  {response.status_code} - {response.text[:100]}", file=sys.stderr)
            return False, None
    except Exception as e:
        print(f"APIè°ƒç”¨å¼‚å¸¸ ({endpoint}): {str(e)}", file=sys.stderr)
        return False, None


def _post_github_api(
    endpoint: str, headers: Dict[str, str], owner: str, repo: str, data: Dict
) -> Tuple[bool, Optional[Dict]]:
    """è°ƒç”¨GitHub APIï¼ˆPOSTï¼‰ï¼Œè¿”å›ï¼ˆæˆåŠŸçŠ¶æ€ï¼Œå“åº”æ•°æ®ï¼‰"""
    url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/{endpoint}"
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code in [200, 201]:
            return True, response.json()
        else:
            print(f"APIé”™è¯¯ ({endpoint}): çŠ¶æ€ç  {response.status_code} - {response.text[:100]}", file=sys.stderr)
            return False, None
    except Exception as e:
        print(f"APIè°ƒç”¨å¼‚å¸¸ ({endpoint}): {str(e)}", file=sys.stderr)
        return False, None


def _patch_github_api(
    endpoint: str, headers: Dict[str, str], owner: str, repo: str, data: Dict
) -> Tuple[bool, Optional[Dict]]:
    """è°ƒç”¨GitHub APIï¼ˆPATCHï¼‰ï¼Œè¿”å›ï¼ˆæˆåŠŸçŠ¶æ€ï¼Œå“åº”æ•°æ®ï¼‰"""
    url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/{endpoint}"
    try:
        response = requests.patch(url, headers=headers, json=data)
        if response.status_code == 200:
            return True, response.json()
        else:
            print(f"APIé”™è¯¯ ({endpoint}): çŠ¶æ€ç  {response.status_code} - {response.text[:100]}", file=sys.stderr)
            return False, None
    except Exception as e:
        print(f"APIè°ƒç”¨å¼‚å¸¸ ({endpoint}): {str(e)}", file=sys.stderr)
        return False, None


def _get_file_content(
    file_path: str,
    headers: Dict[str, str],
    owner: str,
    repo: str,
    ref: str = "main",  # é»˜è®¤ä»mainåˆ†æ”¯è·å–
) -> Optional[str]:
    """ä»æŒ‡å®šåˆ†æ”¯è·å–æ–‡ä»¶å†…å®¹ï¼ˆBase64è§£ç ï¼‰"""
    success, result = _get_github_api(
        f"contents/{file_path}?ref={ref}", headers, owner, repo
    )
    if not success or not result:
        return None

    try:
        content = base64.b64decode(result.get("content", "")).decode("utf-8")
        return content
    except Exception as e:
        print(f"æ–‡ä»¶è§£ç é”™è¯¯ ({file_path}): {e}", file=sys.stderr)
        return None


def _find_pr_by_title(
    title: str, headers: Dict[str, str], owner: str, repo: str
) -> Optional[Dict]:
    """é€šè¿‡ç²¾ç¡®æ ‡é¢˜åŒ¹é…æŸ¥æ‰¾PRï¼ˆæ”¯æŒå·²å…³é—­/æ‰“å¼€çŠ¶æ€ï¼‰"""
    for state in ["closed", "open"]:
        success, prs = _get_github_api(
            f"pulls?state={state}&per_page={CONFIG['CODE_PLATFORM']['api_per_page']}", headers, owner, repo
        )
        if success and prs:
            for pr in prs:
                if pr.get("title") == title:
                    return pr
    return None


def _wait_for_workflow_completion(
    headers: Dict[str, str],
    owner: str,
    repo: str,
    max_wait: int = None
) -> bool:
    """ç­‰å¾…æŒ‡å®šå·¥ä½œæµå®Œæˆï¼ˆé»˜è®¤ä½¿ç”¨CONFIGä¸­çš„max_workflow_waitï¼‰"""
    workflow_file = CONFIG["WORKFLOW"]["workflow_filename"]
    max_wait = max_wait or CONFIG["CODE_PLATFORM"]["max_workflow_wait"]
    print(f"â³ ç­‰å¾… {workflow_file} å·¥ä½œæµå®Œæˆ...")

    start_time = time.time()
    no_workflow_check_count = 0

    while time.time() - start_time < max_wait:
        try:
            success, response = _get_github_api(
                f"actions/workflows/{workflow_file}/runs?per_page=10",
                headers,
                owner,
                repo,
            )

            if success and response:
                runs = response.get("workflow_runs", [])
                if len(runs) > 0:
                    running_count = 0
                    completed_count = 0

                    # æ£€æŸ¥æœ€è¿‘5æ¬¡è¿è¡Œï¼ˆé¿å…å†å²è¿è¡Œå¹²æ‰°ï¼‰
                    for run in runs[:5]:
                        status = run["status"]
                        if status == "completed":
                            completed_count += 1
                        elif status in ["in_progress", "queued"]:
                            running_count += 1

                    print(f"   çŠ¶æ€: {completed_count} å·²å®Œæˆ, {running_count} è¿è¡Œä¸­/æ’é˜Ÿä¸­")

                    if running_count == 0:
                        print(f"âœ… æ‰€æœ‰ {workflow_file} å·¥ä½œæµå·²å®Œæˆ")
                        return True
                else:
                    # æœªæ‰¾åˆ°å·¥ä½œæµè¿è¡Œè®°å½•
                    no_workflow_check_count += 1
                    if no_workflow_check_count == 1:
                        print("   æš‚æœªæ‰¾åˆ°å·¥ä½œæµè¿è¡Œè®°å½•ï¼Œç­‰å¾…5ç§’åé‡è¯•...")
                        time.sleep(5)
                        continue
                    elif no_workflow_check_count >= 2:
                        print(f"âš ï¸ ä¸¤æ¬¡æ£€æŸ¥å‡æœªæ‰¾åˆ° {workflow_file} è¿è¡Œè®°å½•ï¼Œå¯èƒ½æœªè§¦å‘å·¥ä½œæµ")
                        print("   ç»§ç»­æ‰§è¡Œåç»­éªŒè¯...")
                        return False

            print(f"â³ ä»åœ¨ç­‰å¾…... ({int(time.time() - start_time)}ç§’å·²è¿‡å»)")
            time.sleep(10)

        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥å·¥ä½œæµçŠ¶æ€å‡ºé”™: {e}")
            time.sleep(10)

    print(f"âš ï¸ å·¥ä½œæµç­‰å¾…è¶…æ—¶ï¼ˆè¶…è¿‡ {max_wait} ç§’ï¼‰")
    return False


# -----------------------------
# 3) æ ¸å¿ƒæ ¡éªŒå‡½æ•°ï¼ˆæŒ‰æ ¡éªŒç»´åº¦æ‹†åˆ†ï¼Œé€šç”¨æ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def _validate_environment() -> Dict[str, str]:
    """åŠ è½½å¹¶éªŒè¯ç¯å¢ƒå˜é‡ï¼ˆTokenã€ç»„ç»‡åï¼‰"""
    env_config = CONFIG["ENVIRONMENT"]
    load_dotenv(env_config["env_file"])
    
    token = os.environ.get(env_config["token_var"])
    org = os.environ.get(env_config["org_var"])
    
    if not token:
        print(f"é”™è¯¯: ç¯å¢ƒå˜é‡ {env_config['token_var']} æœªåœ¨ {env_config['env_file']} ä¸­è®¾ç½®", file=sys.stderr)
        sys.exit(1)
    if not org:
        print(f"é”™è¯¯: ç¯å¢ƒå˜é‡ {env_config['org_var']} æœªåœ¨ {env_config['env_file']} ä¸­è®¾ç½®", file=sys.stderr)
        sys.exit(1)
        
    return {"token": token, "org": org}


def _verify_workflow_file(
    headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, List[str]]:
    """æ ¡éªŒå·¥ä½œæµæ–‡ä»¶æ˜¯å¦å­˜åœ¨åŠå†…å®¹åˆè§„ï¼ˆè§¦å‘äº‹ä»¶ã€å¿…éœ€ä½œä¸šï¼‰"""
    print("\nğŸ“„ æ ¡éªŒå·¥ä½œæµæ–‡ä»¶...")
    errors = []
    workflow_config = CONFIG["WORKFLOW"]
    workflow_path = workflow_config["file_path"]

    # 1. æ£€æŸ¥å·¥ä½œæµæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆä»ä¸»PRç›®æ ‡åˆ†æ”¯è·å–ï¼‰
    workflow_content = _get_file_content(
        workflow_path, headers, owner, repo, ref=CONFIG["MAIN_PR"]["target_branch"]
    )
    if not workflow_content:
        return False, [f"å·¥ä½œæµæ–‡ä»¶ {workflow_path} åœ¨ {CONFIG['MAIN_PR']['target_branch']} åˆ†æ”¯ä¸­æœªæ‰¾åˆ°"]
    print(f"   âœ… å·¥ä½œæµæ–‡ä»¶ {workflow_path} å­˜åœ¨")

    # 2. æ ¡éªŒPRè§¦å‘äº‹ä»¶é…ç½®
    if f"pull_request:" not in workflow_content:
        errors.append("å·¥ä½œæµç¼ºå°‘ pull_request è§¦å‘é…ç½®")
    else:
        print("   âœ… æ‰¾åˆ° pull_request è§¦å‘é…ç½®")

    # æ ¡éªŒå¿…éœ€è§¦å‘äº‹ä»¶
    missing_triggers = [t for t in workflow_config["required_triggers"] if t not in workflow_content]
    if missing_triggers:
        errors.append(f"ç¼ºå°‘å¿…éœ€è§¦å‘äº‹ä»¶: {missing_triggers}")
    else:
        print(f"   âœ… æ‰¾åˆ°æ‰€æœ‰å¿…éœ€è§¦å‘äº‹ä»¶: {workflow_config['required_triggers']}")

    # 3. æ ¡éªŒå¿…éœ€ä½œä¸š
    missing_jobs = [j for j in workflow_config["required_jobs"] if f"{j}:" not in workflow_content]
    if missing_jobs:
        errors.append(f"ç¼ºå°‘å¿…éœ€ä½œä¸š: {missing_jobs}")
    else:
        print(f"   âœ… æ‰¾åˆ°æ‰€æœ‰å¿…éœ€ä½œä¸š: {workflow_config['required_jobs']}")

    return len(errors) == 0, errors


def _verify_main_pr_merged(
    headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, List[str], Optional[Dict]]:
    """æ ¡éªŒå®ç°PRè‡ªåŠ¨åŒ–çš„ä¸»PRæ˜¯å¦å·²åˆå¹¶ï¼ˆæºåˆ†æ”¯ã€ç›®æ ‡åˆ†æ”¯åˆè§„ï¼‰"""
    print("\nğŸ” æ ¡éªŒä¸»PRåˆå¹¶çŠ¶æ€...")
    errors = []
    pr_config = CONFIG["MAIN_PR"]

    # 1. æŸ¥æ‰¾ä¸»PR
    pr = _find_pr_by_title(pr_config["title"], headers, owner, repo)
    if not pr:
        return False, [f"ä¸»PR '{pr_config['title']}' æœªæ‰¾åˆ°"], None
    pr_number = pr["number"]
    print(f"   æ‰¾åˆ°ä¸»PR #{pr_number}")

    # 2. æ ¡éªŒPRæ˜¯å¦å·²åˆå¹¶
    if not pr.get("merged_at", False):
        errors.append(f"PR #{pr_number} æœªåˆå¹¶")
    else:
        print(f"   âœ… PR #{pr_number} å·²åˆå¹¶")

    # 3. æ ¡éªŒæºåˆ†æ”¯
    if pr.get("head", {}).get("ref") != pr_config["source_branch"]:
        errors.append(f"PR #{pr_number} æºåˆ†æ”¯åº”ä¸º {pr_config['source_branch']}ï¼Œå®é™…ä¸º {pr.get('head', {}).get('ref')}")
    else:
        print(f"   âœ… PR æºåˆ†æ”¯æ­£ç¡®: {pr_config['source_branch']}")

    # 4. æ ¡éªŒç›®æ ‡åˆ†æ”¯
    if pr.get("base", {}).get("ref") != pr_config["target_branch"]:
        errors.append(f"PR #{pr_number} ç›®æ ‡åˆ†æ”¯åº”ä¸º {pr_config['target_branch']}ï¼Œå®é™…ä¸º {pr.get('base', {}).get('ref')}")
    else:
        print(f"   âœ… PR ç›®æ ‡åˆ†æ”¯æ­£ç¡®: {pr_config['target_branch']}")

    return len(errors) == 0, errors, pr


def _verify_workflow_runs(
    pr_data: Dict, headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, List[str]]:
    """æ ¡éªŒä¸»PRçš„å·¥ä½œæµè¿è¡ŒçŠ¶æ€ï¼ˆä½œä¸šå­˜åœ¨ã€æˆåŠŸã€å¹¶è¡Œæ‰§è¡Œï¼‰"""
    print("\nâš™ï¸ æ ¡éªŒå·¥ä½œæµè¿è¡ŒçŠ¶æ€...")
    errors = []
    workflow_config = CONFIG["WORKFLOW"]
    pr_number = pr_data["number"]
    pr_head_sha = pr_data.get("head", {}).get("sha")
    pr_head_ref = pr_data.get("head", {}).get("ref")

    # 1. è·å–ä¸»PRå…³è”çš„å·¥ä½œæµè¿è¡Œè®°å½•
    success, runs_response = _get_github_api(
        f"actions/runs?event=pull_request&per_page={CONFIG['CODE_PLATFORM']['api_per_page']}", headers, owner, repo
    )
    if not success:
        return False, ["è·å–å·¥ä½œæµè¿è¡Œè®°å½•å¤±è´¥"]

    # ç­›é€‰ä¸»PRçš„è¿è¡Œè®°å½•ï¼ˆé€šè¿‡SHAæˆ–åˆ†æ”¯åŒ¹é…ï¼‰
    pr_runs = []
    for run in runs_response.get("workflow_runs", []):
        if pr_head_sha and run.get("head_sha") == pr_head_sha:
            pr_runs.append(run)
            continue
        if pr_head_ref and run.get("head_branch") == pr_head_ref:
            pr_runs.append(run)
            continue

    if not pr_runs:
        return False, [f"æœªæ‰¾åˆ°PR #{pr_number} çš„å·¥ä½œæµè¿è¡Œè®°å½•ï¼ˆSHA: {pr_head_sha}ï¼Œåˆ†æ”¯: {pr_head_ref}ï¼‰"]
    print(f"   æ‰¾åˆ° PR #{pr_number} çš„ {len(pr_runs)} æ¡å·¥ä½œæµè¿è¡Œè®°å½•")

    # 2. æ ¡éªŒæœ€æ–°è¿è¡Œæ˜¯å¦æˆåŠŸ
    latest_run = pr_runs[0]  # GitHubæŒ‰åˆ›å»ºæ—¶é—´é™åºè¿”å›ï¼Œå–ç¬¬ä¸€æ¡ä¸ºæœ€æ–°
    run_id = latest_run["id"]
    if latest_run["conclusion"] != "success":
        errors.append(f"æœ€æ–°å·¥ä½œæµè¿è¡Œï¼ˆID: {run_id}ï¼‰æœªæˆåŠŸï¼Œç»“è®º: {latest_run['conclusion']}")
    else:
        print(f"   âœ… æœ€æ–°å·¥ä½œæµè¿è¡Œï¼ˆID: {run_id}ï¼‰æˆåŠŸ")

    # 3. æ ¡éªŒå¿…éœ€ä½œä¸šæ˜¯å¦å­˜åœ¨ä¸”æˆåŠŸ
    success, jobs_response = _get_github_api(f"actions/runs/{run_id}/jobs", headers, owner, repo)
    if not success:
        return False, [f"è·å–å·¥ä½œæµè¿è¡Œï¼ˆID: {run_id}ï¼‰çš„ä½œä¸šè®°å½•å¤±è´¥"]

    jobs = jobs_response.get("jobs", [])
    found_jobs = [job["name"] for job in jobs]
    missing_jobs = [j for j in workflow_config["required_jobs"] if j not in found_jobs]
    if missing_jobs:
        errors.append(f"ç¼ºå°‘å¿…éœ€ä½œä¸š: {missing_jobs}ï¼Œå·²æ‰¾åˆ°: {found_jobs}")
    else:
        print(f"   âœ… æ‰¾åˆ°æ‰€æœ‰å¿…éœ€ä½œä¸š: {found_jobs}")

    # æ ¡éªŒæ‰€æœ‰ä½œä¸šæ˜¯å¦æˆåŠŸ
    failed_jobs = [job["name"] for job in jobs if job["conclusion"] != "success"]
    if failed_jobs:
        errors.append(f"ä»¥ä¸‹ä½œä¸šæ‰§è¡Œå¤±è´¥: {failed_jobs}")
    else:
        print("   âœ… æ‰€æœ‰ä½œä¸šæ‰§è¡ŒæˆåŠŸ")

    # 4. æ ¡éªŒä½œä¸šæ˜¯å¦å¹¶è¡Œæ‰§è¡Œï¼ˆå¯åŠ¨æ—¶é—´å·®â‰¤é˜ˆå€¼ï¼‰
    if len(jobs) >= len(workflow_config["required_jobs"]):
        start_times = [job["started_at"] for job in jobs if job["started_at"]]
        if len(start_times) >= len(workflow_config["required_jobs"]):
            start_dt = [datetime.datetime.fromisoformat(t.replace("Z", "+00:00")) for t in start_times]
            time_diff = (max(start_dt) - min(start_dt)).total_seconds()
            if time_diff > workflow_config["parallel_check_threshold"]:
                errors.append(f"ä½œä¸šæœªå¹¶è¡Œæ‰§è¡Œï¼ˆæ—¶é—´å·®: {time_diff:.0f}ç§’ï¼Œé˜ˆå€¼: {workflow_config['parallel_check_threshold']}ç§’ï¼‰")
            else:
                print(f"   âœ… ä½œä¸šå¹¶è¡Œæ‰§è¡Œï¼ˆæ—¶é—´å·®: {time_diff:.0f}ç§’ï¼‰")
        else:
            errors.append("ä½œä¸šå¯åŠ¨æ—¶é—´ä¸è¶³ï¼Œæ— æ³•éªŒè¯å¹¶è¡Œæ‰§è¡Œ")

    return len(errors) == 0, errors


def _verify_pr_comments(
    pr_data: Dict, headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, List[str]]:
    """æ ¡éªŒPRæ˜¯å¦åŒ…å«è‡ªåŠ¨åŒ–æœºå™¨äººçš„å¿…éœ€æŠ¥å‘Šè¯„è®º"""
    print("\nğŸ’¬ æ ¡éªŒPRè‡ªåŠ¨åŒ–è¯„è®º...")
    errors = []
    comment_config = CONFIG["PR_COMMENT"]
    pr_number = pr_data["number"]

    # 1. è·å–PRè¯„è®º
    success, comments = _get_github_api(f"issues/{pr_number}/comments", headers, owner, repo)
    if not success:
        return False, ["è·å–PRè¯„è®ºå¤±è´¥"]

    # ç­›é€‰è‡ªåŠ¨åŒ–æœºå™¨äººçš„è¯„è®º
    bot_comments = [c for c in comments if c.get("user", {}).get("login") == comment_config["bot_login"]]
    if not bot_comments:
        return False, [f"æœªæ‰¾åˆ° {comment_config['bot_login']} çš„è¯„è®º"]
    print(f"   æ‰¾åˆ° {comment_config['bot_login']} çš„ {len(bot_comments)} æ¡è¯„è®º")

    # 2. æ ¡éªŒå¿…éœ€æŠ¥å‘Šæ˜¯å¦é½å…¨
    bot_comment_bodies = [c.get("body", "") for c in bot_comments]
    required_reports = comment_config["required_reports"]
    found_reports = []

    for report in required_reports:
        report_found = False
        for body in bot_comment_bodies:
            if any(keyword in body for keyword in report["main_keywords"]):
                report_found = True
                # æ ¡éªŒå­å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
                missing_sub = [k for k in report["sub_keywords"] if k not in body]
                if missing_sub:
                    errors.append(f"{report['name']} ç¼ºå°‘å­å…³é”®è¯: {missing_sub}")
                else:
                    print(f"   âœ… æ‰¾åˆ° {report['name']}")
                break
        if not report_found:
            errors.append(f"ç¼ºå°‘ {report['name']}ï¼ˆä¸»å…³é”®è¯: {report['main_keywords']}ï¼‰")
        else:
            found_reports.append(report["name"])

    # æ ¡éªŒæŠ¥å‘Šæ•°é‡æ˜¯å¦ç¬¦åˆé¢„æœŸ
    if len(found_reports) != len(required_reports):
        errors.append(f"é¢„æœŸ {len(required_reports)} ä»½æŠ¥å‘Šï¼Œå®é™…æ‰¾åˆ° {len(found_reports)} ä»½")
    else:
        print(f"   âœ… æ‰€æœ‰ {len(required_reports)} ä»½å¿…éœ€æŠ¥å‘Šé½å…¨")

    return len(errors) == 0, errors


def _run_unit_tests(
    headers: Dict[str, str], owner: str, repo: str
) -> Tuple[bool, List[str]]:
    """åˆ›å»ºå«æ•…æ„é”™è¯¯çš„æµ‹è¯•PRï¼Œæ ¡éªŒå·¥ä½œæµæ˜¯å¦æ­£ç¡®è¯†åˆ«å¤±è´¥åœºæ™¯"""
    print("\nğŸ§ª æ‰§è¡Œå¤±è´¥åœºæ™¯å•å…ƒæµ‹è¯•...")
    errors = []
    test_config = CONFIG["UNIT_TEST"]
    created_prs = []

    # éå†æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
    for idx, test_case in enumerate(test_config["test_cases"]):
        print(f"\n   å¤„ç†æµ‹è¯•ç”¨ä¾‹ {idx+1}: {test_case['title']}")

        # 1. åˆ›å»ºæµ‹è¯•åˆ†æ”¯ï¼ˆè‹¥å·²å­˜åœ¨åˆ™åˆ é™¤é‡å»ºï¼‰
        branch = test_case["branch"]
        # è·å–ç›®æ ‡åˆ†æ”¯çš„SHAï¼ˆç”¨äºåˆ›å»ºæ–°åˆ†æ”¯ï¼‰
        success, target_ref = _get_github_api(
            f"git/ref/heads/{CONFIG['MAIN_PR']['target_branch']}", headers, owner, repo
        )
        if not success:
            errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: æ— æ³•è·å– {CONFIG['MAIN_PR']['target_branch']} åˆ†æ”¯çš„å¼•ç”¨")
            continue

        target_sha = target_ref["object"]["sha"]
        branch_data = {"ref": f"refs/heads/{branch}", "sha": target_sha}

        # å°è¯•åˆ›å»ºåˆ†æ”¯ï¼Œè‹¥å·²å­˜åœ¨åˆ™åˆ é™¤åé‡è¯•
        success, _ = _post_github_api("git/refs", headers, owner, repo, branch_data)
        if not success:
            print(f"   åˆ†æ”¯ {branch} å·²å­˜åœ¨ï¼Œå°è¯•åˆ é™¤åé‡å»º...")
            # åˆ é™¤å·²å­˜åœ¨çš„åˆ†æ”¯
            delete_url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/git/refs/heads/{branch}"
            delete_response = requests.delete(delete_url, headers=headers)
            if delete_response.status_code != 204:
                errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: æ— æ³•åˆ é™¤å·²å­˜åœ¨çš„åˆ†æ”¯ {branch}")
                continue
            time.sleep(2)  # ç­‰å¾…2ç§’ç¡®ä¿åˆ é™¤ç”Ÿæ•ˆ
            # é‡æ–°åˆ›å»ºåˆ†æ”¯
            success, _ = _post_github_api("git/refs", headers, owner, repo, branch_data)
            if not success:
                errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: é‡å»ºåˆ†æ”¯ {branch} å¤±è´¥")
                continue
        print(f"   âœ… æˆåŠŸåˆ›å»ºæµ‹è¯•åˆ†æ”¯ {branch}")

        # 2. åˆ›å»º/æ›´æ–°æµ‹è¯•æ–‡ä»¶ï¼ˆå«æ•…æ„é”™è¯¯ï¼‰
        file_path = test_case["file_path"]
        file_content = base64.b64encode(test_case["content"].encode()).decode()
        file_data = {
            "message": f"æµ‹è¯•æäº¤: {test_case['title']}",
            "content": file_content,
            "branch": branch
        }

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆå­˜åœ¨åˆ™éœ€ä¼ å…¥SHAæ›´æ–°ï¼‰
        success, file_info = _get_github_api(f"contents/{file_path}?ref={CONFIG['MAIN_PR']['target_branch']}", headers, owner, repo)
        if success and file_info:
            file_data["sha"] = file_info["sha"]

        # ä¸Šä¼ æ–‡ä»¶ï¼ˆPUTæ–¹æ³•æ”¯æŒåˆ›å»º/æ›´æ–°ï¼‰
        file_url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/contents/{file_path}"
        try:
            response = requests.put(file_url, headers=headers, json=file_data)
            if response.status_code not in [200, 201]:
                errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: ä¸Šä¼ æ–‡ä»¶ {file_path} å¤±è´¥ï¼ˆçŠ¶æ€ç : {response.status_code}ï¼‰")
                continue
        except Exception as e:
            errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: ä¸Šä¼ æ–‡ä»¶ {file_path} å¼‚å¸¸: {str(e)}")
            continue
        print(f"   âœ… æˆåŠŸä¸Šä¼ æµ‹è¯•æ–‡ä»¶ {file_path}")

        # 3. åˆ›å»ºæµ‹è¯•PR
        pr_data = {
            "title": test_case["title"],
            "head": branch,
            "base": CONFIG["MAIN_PR"]["target_branch"],
            "body": f"æµ‹è¯•PR: éªŒè¯å·¥ä½œæµæ˜¯å¦æ­£ç¡®è¯†åˆ« {test_case['expected_failure']} å¤±è´¥åœºæ™¯"
        }
        success, pr_response = _post_github_api("pulls", headers, owner, repo, pr_data)
        if not success:
            errors.append(f"æµ‹è¯•ç”¨ä¾‹ {idx+1} å¤±è´¥: åˆ›å»ºæµ‹è¯•PRå¤±è´¥")
            continue
        pr_number = pr_response["number"]
        created_prs.append({"number": pr_number, "branch": branch})
        print(f"   âœ… æˆåŠŸåˆ›å»ºæµ‹è¯•PR #{pr_number}")

    # 4. ç­‰å¾…æµ‹è¯•PRçš„å·¥ä½œæµå®Œæˆå¹¶æ ¡éªŒç»“æœ
    if created_prs:
        print(f"\n   ç­‰å¾… {len(created_prs)} ä¸ªæµ‹è¯•PRçš„å·¥ä½œæµå®Œæˆï¼ˆæœ€å¤§ç­‰å¾… {test_config['max_test_wait']} ç§’ï¼‰...")
        time.sleep(5)  # ç­‰å¾…å·¥ä½œæµè§¦å‘
        _wait_for_workflow_completion(headers, owner, repo, max_wait=test_config["max_test_wait"])

        # æ ¡éªŒæ¯ä¸ªæµ‹è¯•PRçš„å·¥ä½œæµæ˜¯å¦æ­£ç¡®å¤±è´¥
        for idx, pr_info in enumerate(created_prs):
            pr_number = pr_info["number"]
            test_case = test_config["test_cases"][idx]
            # è·å–PRçš„å·¥ä½œæµè¿è¡Œè®°å½•
            success, runs_response = _get_github_api(
                f"actions/runs?event=pull_request&per_page=5", headers, owner, repo
            )
            if not success:
                errors.append(f"æµ‹è¯•PR #{pr_number} æ ¡éªŒå¤±è´¥: æ— æ³•è·å–å·¥ä½œæµè®°å½•")
                continue

            # ç­›é€‰è¯¥PRçš„è¿è¡Œè®°å½•
            pr_runs = []
            for run in runs_response.get("workflow_runs", []):
                for pr in run.get("pull_requests", []):
                    if pr.get("number") == pr_number:
                        pr_runs.append(run)
                        break

            if not pr_runs:
                errors.append(f"æµ‹è¯•PR #{pr_number} æ ¡éªŒå¤±è´¥: æœªæ‰¾åˆ°å·¥ä½œæµè®°å½•")
                continue

            # æ ¡éªŒæœ€æ–°è¿è¡Œæ˜¯å¦å¤±è´¥
            latest_run = pr_runs[0]
            if latest_run["conclusion"] != "failure":
                errors.append(f"æµ‹è¯•PR #{pr_number} æ ¡éªŒå¤±è´¥: é¢„æœŸ {test_case['expected_failure']} å¤±è´¥ï¼Œå®é™…ç»“è®º: {latest_run['conclusion']}")
            else:
                print(f"   âœ… æµ‹è¯•PR #{pr_number} æ­£ç¡®è¯†åˆ« {test_case['expected_failure']} å¤±è´¥åœºæ™¯")

    # 5. æ¸…ç†æµ‹è¯•PRå’Œåˆ†æ”¯ï¼ˆè‹¥å¯ç”¨æ¸…ç†ï¼‰
    if test_config["cleanup_enabled"] and created_prs:
        print("\n   æ¸…ç†æµ‹è¯•PRå’Œåˆ†æ”¯...")
        for pr_info in created_prs:
            pr_number = pr_info["number"]
            branch = pr_info["branch"]
            # å…³é—­PR
            success, _ = _patch_github_api(f"pulls/{pr_number}", headers, owner, repo, {"state": "closed"})
            if success:
                print(f"   âœ… å…³é—­æµ‹è¯•PR #{pr_number}")
            else:
                errors.append(f"æ¸…ç†å¤±è´¥: æ— æ³•å…³é—­æµ‹è¯•PR #{pr_number}")
            # åˆ é™¤åˆ†æ”¯
            delete_url = f"https://api.{CONFIG['CODE_PLATFORM']['api_domain']}/repos/{owner}/{repo}/git/refs/heads/{branch}"
            delete_response = requests.delete(delete_url, headers=headers)
            if delete_response.status_code == 204:
                print(f"   âœ… åˆ é™¤æµ‹è¯•åˆ†æ”¯ {branch}")
            else:
                errors.append(f"æ¸…ç†å¤±è´¥: æ— æ³•åˆ é™¤æµ‹è¯•åˆ†æ”¯ {branch}")

    return len(errors) == 0, errors


# -----------------------------
# 4) ä¸»æ ¡éªŒæµç¨‹ï¼ˆé€šç”¨æ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def verify_pr_automation_workflow() -> bool:
    """æ‰§è¡ŒPRè‡ªåŠ¨åŒ–å·¥ä½œæµçš„å®Œæ•´æ ¡éªŒ"""
    # 1. åŠ è½½ç¯å¢ƒé…ç½®
    print("ğŸ” å¯åŠ¨PRè‡ªåŠ¨åŒ–å·¥ä½œæµéªŒè¯ï¼ˆæ ·ä¾‹ï¼šweb-applicationä»“åº“ï¼‰")
    print("=" * 60)
    print("1. åŠ è½½ç¯å¢ƒé…ç½®...")
    env_data = _validate_environment()
    github_token = env_data["token"]
    github_org = env_data["org"]
    repo = CONFIG["CODE_PLATFORM"]["target_repo"]

    # æ„å»ºAPIè¯·æ±‚å¤´
    headers = {
        "Authorization": f"{CONFIG['CODE_PLATFORM']['auth_scheme']} {github_token}",
        "Accept": f"application/vnd.{CONFIG['CODE_PLATFORM']['api_domain'].split('.')[0]}.v3+json"
    }
    print("âœ“ ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ")

    # 2. æ‰§è¡Œå„ç»´åº¦æ ¡éªŒ
    all_passed = True
    pr_data = None

    # 2.1 æ ¡éªŒå·¥ä½œæµæ–‡ä»¶
    workflow_ok, workflow_errors = _verify_workflow_file(headers, github_org, repo)
    if not workflow_ok:
        all_passed = False
        print("âŒ å·¥ä½œæµæ–‡ä»¶æ ¡éªŒå¤±è´¥:")
        for err in workflow_errors:
            print(f"   - {err}")
    else:
        print("âœ… å·¥ä½œæµæ–‡ä»¶æ ¡éªŒé€šè¿‡")

    # 2.2 æ ¡éªŒä¸»PRåˆå¹¶çŠ¶æ€
    pr_ok, pr_errors, pr_data = _verify_main_pr_merged(headers, github_org, repo)
    if not pr_ok:
        all_passed = False
        print("âŒ ä¸»PRæ ¡éªŒå¤±è´¥:")
        for err in pr_errors:
            print(f"   - {err}")
    else:
        print("âœ… ä¸»PRæ ¡éªŒé€šè¿‡")

    # 2.3 æ ¡éªŒå·¥ä½œæµè¿è¡ŒçŠ¶æ€ï¼ˆä»…ä¸»PRæ ¡éªŒé€šè¿‡æ—¶æ‰§è¡Œï¼‰
    if pr_ok and pr_data:
        runs_ok, runs_errors = _verify_workflow_runs(pr_data, headers, github_org, repo)
        if not runs_ok:
            all_passed = False
            print("âŒ å·¥ä½œæµè¿è¡Œæ ¡éªŒå¤±è´¥:")
            for err in runs_errors:
                print(f"   - {err}")
        else:
            print("âœ… å·¥ä½œæµè¿è¡Œæ ¡éªŒé€šè¿‡")

        # 2.4 æ ¡éªŒPRè‡ªåŠ¨åŒ–è¯„è®ºï¼ˆä»…ä¸»PRæ ¡éªŒé€šè¿‡æ—¶æ‰§è¡Œï¼‰
        comments_ok, comments_errors = _verify_pr_comments(pr_data, headers, github_org, repo)
        if not comments_ok:
            all_passed = False
            print("âŒ PRè¯„è®ºæ ¡éªŒå¤±è´¥:")
            for err in comments_errors:
                print(f"   - {err}")
        else:
            print("âœ… PRè¯„è®ºæ ¡éªŒé€šè¿‡")

    # 2.5 æ‰§è¡Œå¤±è´¥åœºæ™¯å•å…ƒæµ‹è¯•
    tests_ok, tests_errors = _run_unit_tests(headers, github_org, repo)
    if not tests_ok:
        all_passed = False
        print("âŒ å•å…ƒæµ‹è¯•å¤±è´¥:")
        for err in tests_errors:
            print(f"   - {err}")
    else:
        print("âœ… å•å…ƒæµ‹è¯•é€šè¿‡")

    # 3. è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰PRè‡ªåŠ¨åŒ–å·¥ä½œæµæ ¡éªŒé€šè¿‡!ï¼ˆæ ·ä¾‹ï¼šweb-applicationä»“åº“ï¼‰")
        print("\nğŸ“‹ æ ¡éªŒæ€»ç»“:")
        print(f"   âœ… å·¥ä½œæµæ–‡ä»¶ {CONFIG['WORKFLOW']['file_path']} åˆè§„ï¼ˆå«è§¦å‘äº‹ä»¶+4ç±»ä½œä¸šï¼‰")
        print(f"   âœ… ä¸»PR #{pr_data['number']} ä» {CONFIG['MAIN_PR']['source_branch']} åˆå¹¶åˆ° {CONFIG['MAIN_PR']['target_branch']}")
        print(f"   âœ… å·¥ä½œæµè¿è¡ŒæˆåŠŸï¼Œ4ç±»ä½œä¸šå¹¶è¡Œæ‰§è¡Œï¼ˆæ—¶é—´å·®â‰¤{CONFIG['WORKFLOW']['parallel_check_threshold']}ç§’ï¼‰")
        print(f"   âœ… PRå« {len(CONFIG['PR_COMMENT']['required_reports'])} ç±»è‡ªåŠ¨åŒ–æŠ¥å‘Šï¼ˆ{CONFIG['PR_COMMENT']['bot_login']} æœºå™¨äººï¼‰")
        print(f"   âœ… 4ç±»å¤±è´¥åœºæ™¯æµ‹è¯•é€šè¿‡ï¼ˆå·¥ä½œæµæ­£ç¡®æ‹¦æˆªé”™è¯¯PRï¼‰")
        print(f"\nğŸ¤– web-applicationä»“åº“PRè‡ªåŠ¨åŒ–å·¥ä½œæµè¿è¡Œæ­£å¸¸!")
    else:
        print("âŒ PRè‡ªåŠ¨åŒ–å·¥ä½œæµæ ¡éªŒå¤±è´¥!ï¼ˆæ ·ä¾‹ï¼šweb-applicationä»“åº“ï¼‰")
        print("   éƒ¨åˆ†æ ¡éªŒé¡¹æœªæ»¡è¶³é¢„æœŸè¦æ±‚ï¼Œè¯·æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®æ­£ã€‚")

    return all_passed


# -----------------------------
# 5) è„šæœ¬å…¥å£
# -----------------------------
if __name__ == "__main__":
    success = verify_pr_automation_workflow()
    sys.exit(0 if success else 1)
